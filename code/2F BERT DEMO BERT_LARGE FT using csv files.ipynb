{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model to further fine tune the 'bert-large-uncased-whole-word-masking-finetuned-squad' pre-trained model\n",
    "This model allows you to further fine-tune the pre-trained and fine tuned 'bert-large-uncased-whole-word-masking-finetuned-squad' used in the 2P DEMO BERT legal predict.ipynb notebook.\n",
    "The notebook requires that you have a .csv file available with the folliwing column headers:\n",
    "- 'context' - This is the text which you are trying to extract the answer from\n",
    "- 'question' - This is the question being asked\n",
    "- 'answer' - This is the answer, which must be in the 'context' character for character\n",
    "- 'answer_start' - This is the start character of the 'answer' within the 'context'\n",
    "\n",
    "The model expects a .csv as input, and carries out the following:\n",
    "- prepares the data to enable fine tuning of the 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "- tokenised the data\n",
    "- trains the model using an AdamW optimizer using the pytorch library\n",
    "- save the model\n",
    "- carries out validation, using a separate carved out validation dataset\n",
    "- Enables prediction using the new fine-tuned model on your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForQuestionAnswering, AdamW, AutoTokenizer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Load tokenizer - Need to use the BERT tokenizer, as other tokenizers not accepted\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small dataset for fine tuning\n",
    "\n",
    "# Replace with your own dataset\n",
    "datasets = pd.read_csv('/home/malmason/datasets/squad_csv/SQuAD_csv_sm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data where answer not in context\n",
    "array = []\n",
    "for i in range(len(datasets)):\n",
    "    if datasets['answer'][i] not in datasets['context'][i]:\n",
    "        array.append(i)\n",
    "datasets.drop(datasets.index[array], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the dataset\n",
    "datasets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets answers and answer start points as dictionary items\n",
    "data_answers = []\n",
    "temp_data = {}\n",
    "for answer, answer_start in zip(datasets.answer, datasets.answer_start):\n",
    "    temp_data['text'] = str(answer)\n",
    "    temp_data['answer_start'] = int(answer_start)\n",
    "    dict_copy = temp_data.copy()\n",
    "    data_answers.append(dict_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get context containing answer and the answer itself\n",
    "data_contexts = datasets.context\n",
    "data_questions = datasets.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and val datasets as needed based on your fine tuning data\n",
    "train_answers = data_answers[:80000]\n",
    "val_answers = data_answers[80000:]\n",
    "train_contexts = data_contexts[:80000]\n",
    "val_contexts = data_contexts[80000:]\n",
    "train_questions = data_questions[:80000]\n",
    "val_questions = data_questions[80000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look to see output is as expected\n",
    "print(data_contexts[0], data_questions[0], data_answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add answer end character to data\n",
    "def add_end_idx(answers, contexts):\n",
    "\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        \n",
    "        # refers to text we expect to find in context\n",
    "        gold_text = str(answer['text'])\n",
    "        \n",
    "        # get start index\n",
    "        start_idx = answer['answer_start']\n",
    "        \n",
    "        # coonvert data type to int\n",
    "        start_idx = int(start_idx)\n",
    "        \n",
    "        # record end index position\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "\n",
    "        # Adjust in case the end index is off\n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            for n in [1, 2]:\n",
    "                if context[start_idx-n:end_idx-n] == gold_text:\n",
    "                    answer['answer_start'] = start_idx - n\n",
    "                    answer['answer_end'] = end_idx - n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function add_end_index\n",
    "add_end_idx(train_answers, train_contexts)\n",
    "add_end_idx(val_answers, val_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify answer_end is there, as can sometimes be missing if answer not where expected\n",
    "count = 0\n",
    "for answer in (train_answers):\n",
    "    if 'answer_end' not in answer:\n",
    "        print(answer, count)\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train and val contexts, questions and answers to lists\n",
    "train_contexts = list(train_contexts)\n",
    "train_questions = list(train_questions)\n",
    "val_contexts = list(val_contexts)\n",
    "val_questions = list(val_questions)\n",
    "train_answers = list(train_answers)\n",
    "val_answers = list(val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call tokenizer for training and val data\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_token_positions(encodings, answers):\n",
    "    # initialize lists to contain the token indices of answer start/end\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    \n",
    "    for i in range(len(answers)):\n",
    "\n",
    "        # append start/end token position using char_to_token method\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n",
    "\n",
    "        # truncate if start position is none\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        # find end token\n",
    "        shift = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n",
    "            shift += 1\n",
    "    # update tokenised data with start and end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call add_token_position function\n",
    "add_token_positions(train_encodings, train_answers)\n",
    "add_token_positions(val_encodings, val_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check keys are there. Will be different based on BERT model used\n",
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check encoding - Format is: Context starts with start token [CLS], and finishes with [SEP], where the question follows\n",
    "print(val_encodings[40].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring data together for train and val encodings\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if it exists, else CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Use GPU\n",
    "model.to(device)\n",
    "# set train mode\n",
    "model.train()\n",
    "# set learning rate\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# initialize data loader with batch size that will fit GPU\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize gradients\n",
    "        optim.zero_grad()\n",
    "        # get inputs and send to GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        # train model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions,\n",
    "                        end_positions=end_positions)\n",
    "        # get loss\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and tokenizer\n",
    "model_path = 'models/bert-large-uncased-whole-word-masking-finetuned-squad-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluate\n",
    "model.eval()\n",
    "\n",
    "# Use dataloader with batch size to load val data\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "acc = []\n",
    "\n",
    "loop = tqdm(val_loader)\n",
    "\n",
    "for batch in loop:\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        # predict\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # get start and end predictions from outputs\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        # calculate accuracy for both and append to accuracy list\n",
    "        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n",
    "# calculate average accuracy in total\n",
    "acc = sum(acc)/len(acc)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text extractor and natural language tool kit\n",
    "from pdfminer.high_level import extract_text\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an agreement\n",
    "filename = 'DEMO_VitalibisInc_20180316_8-K_EX-10.2_11100168_EX-10.2_Hosting Agreement.pdf'\n",
    "doc = extract_text(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove characters not desired in text\n",
    "book = doc.replace(\"\\n\" , \"\")\n",
    "book = book.replace(\"\\x0c\", \"\")\n",
    "book = book.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break book into sentences\n",
    "sent_corpus = nltk.sent_tokenize(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, sent_corpus):\n",
    "    max_prob = -10.0\n",
    "    \n",
    "    # loop through sentences\n",
    "    for sent in sent_corpus:\n",
    "        \n",
    "        # Convert text to string\n",
    "        text = str(sent)\n",
    "        \n",
    "        # Tokenise the question and text\n",
    "        inputs = tokenizer(question, text, add_special_tokens=True, max_length=512, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "        text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        \n",
    "        # Run the tokenised text through the pre-trained auto model for  question answering, and store outputs\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Get start and end scores for each sentence from the model output\n",
    "        answer_start_scores = outputs.start_logits\n",
    "        answer_end_scores = outputs.end_logits\n",
    "\n",
    "        # Get location of maximum start score\n",
    "        answer_start = torch.argmax(answer_start_scores)\n",
    "        answer_end = torch.argmax(answer_end_scores) + 1 \n",
    "        \n",
    "        # Get the maximum start and end probabilities\n",
    "        max_prob_start = torch.max(answer_start_scores)\n",
    "        max_prob_end = torch.max(answer_end_scores)\n",
    "        \n",
    "        # Sum the maximum start and end probabilities\n",
    "        max_prob_startend = max_prob_start + max_prob_end\n",
    "        \n",
    "        # Check of score of prediction for sentence is higher than previously recorded\n",
    "        if max_prob_startend > max_prob:\n",
    "            max_prob = max_prob_startend\n",
    "            \n",
    "            # Convert answer tokens to string\n",
    "            answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "            # Store context where the answer was derived from as text answer\n",
    "            text_answer = text\n",
    "            \n",
    "    print('BERT Answer:\\n------------\\n', answer, '\\n\\nSentence:\\n---------\\n', text_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer('Which two parties is the agreement between?', sent_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer('When is the agreement dated?', sent_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
